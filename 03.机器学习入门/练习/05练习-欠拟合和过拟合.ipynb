{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**This notebook is an exercise in the [Introduction to Machine Learning](https://www.kaggle.com/learn/intro-to-machine-learning) course.  You can reference the tutorial at [this link](https://www.kaggle.com/dansbecker/underfitting-and-overfitting).**\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 回顾\n",
    "您已经构建了第一个模型，现在是时候优化树的大小以做出更好的预测了。运行此单元格以在上一步中断的地方设置您的编码环境。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-28T16:30:38.993243Z",
     "iopub.status.busy": "2022-06-28T16:30:38.992849Z",
     "iopub.status.idle": "2022-06-28T16:30:39.046556Z",
     "shell.execute_reply": "2022-06-28T16:30:39.045348Z",
     "shell.execute_reply.started": "2022-06-28T16:30:38.993214Z"
    }
   },
   "outputs": [],
   "source": [
    "# Code you have previously used to load data\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "\n",
    "# Path of the file to read\n",
    "iowa_file_path = '../input/home-data-for-ml-course/train.csv'\n",
    "\n",
    "home_data = pd.read_csv(iowa_file_path)\n",
    "# Create target object and call it y\n",
    "y = home_data.SalePrice\n",
    "# Create X\n",
    "features = ['LotArea', 'YearBuilt', '1stFlrSF', '2ndFlrSF', 'FullBath', 'BedroomAbvGr', 'TotRmsAbvGrd']\n",
    "X = home_data[features]\n",
    "\n",
    "# Split into validation and training data\n",
    "train_X, val_X, train_y, val_y = train_test_split(X, y, random_state=1)\n",
    "\n",
    "# Specify Model\n",
    "iowa_model = DecisionTreeRegressor(random_state=1)\n",
    "# Fit Model\n",
    "iowa_model.fit(train_X, train_y)\n",
    "\n",
    "# Make validation predictions and calculate mean absolute error\n",
    "val_predictions = iowa_model.predict(val_X)\n",
    "val_mae = mean_absolute_error(val_predictions, val_y)\n",
    "print(\"Validation MAE: {:,.0f}\".format(val_mae))\n",
    "\n",
    "# Set up code checking\n",
    "from learntools.core import binder\n",
    "binder.bind(globals())\n",
    "from learntools.machine_learning.ex5 import *\n",
    "print(\"\\nSetup complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 练习\n",
    "\n",
    "您可以自己编写函数`get_mae`。现在，我们来提供。这个函数与上一课中介绍的是同一个函数。查看下面的代码块。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-28T16:30:39.049544Z",
     "iopub.status.busy": "2022-06-28T16:30:39.049104Z",
     "iopub.status.idle": "2022-06-28T16:30:39.056184Z",
     "shell.execute_reply": "2022-06-28T16:30:39.055311Z",
     "shell.execute_reply.started": "2022-06-28T16:30:39.049503Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_mae(max_leaf_nodes, train_X, val_X, train_y, val_y):\n",
    "    model = DecisionTreeRegressor(max_leaf_nodes=max_leaf_nodes, random_state=0)\n",
    "    model.fit(train_X, train_y)\n",
    "    preds_val = model.predict(val_X)\n",
    "    mae = mean_absolute_error(val_y, preds_val)\n",
    "    return(mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 步骤1: 比较不同大小的决策树\n",
    "\n",
    "编写一个循环，从一组可能的值中尝试以下 *max_leaf_node* 值。\n",
    "\n",
    "对 max_leaf_node 的每个值调用 *get_mae* 函数。以某种方式存储输出，使您能够选择 `max_leaf_nodes` 的值，从而为您的数据提供最准确的模型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-28T16:30:39.058058Z",
     "iopub.status.busy": "2022-06-28T16:30:39.057277Z",
     "iopub.status.idle": "2022-06-28T16:30:39.125947Z",
     "shell.execute_reply": "2022-06-28T16:30:39.125215Z",
     "shell.execute_reply.started": "2022-06-28T16:30:39.058014Z"
    }
   },
   "outputs": [],
   "source": [
    "candidate_max_leaf_nodes = [5, 25, 50, 100, 250, 500]\n",
    "\n",
    "# 编写循环，从 candidate_max_leaf_nodes 中找到理想的树大小\n",
    "scores = {leaf_size: get_mae(leaf_size, train_X, val_X, train_y, val_y) for leaf_size in candidate_max_leaf_nodes}\n",
    "\n",
    "# 保存 max_leaf_node 的最佳值(它应该是5、25、50、100、250或500)\n",
    "best_tree_size = min(scores, key=scores.get)\n",
    "\n",
    "# Check your answer\n",
    "step_1.check()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-28T16:30:39.128560Z",
     "iopub.status.busy": "2022-06-28T16:30:39.128009Z",
     "iopub.status.idle": "2022-06-28T16:30:39.132172Z",
     "shell.execute_reply": "2022-06-28T16:30:39.131345Z",
     "shell.execute_reply.started": "2022-06-28T16:30:39.128529Z"
    }
   },
   "outputs": [],
   "source": [
    "# The lines below will show you a hint or the solution.\n",
    "# step_1.hint() \n",
    "# step_1.solution()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 步骤2: 使用所有数据拟合模型\n",
    "\n",
    "你知道最好的树大小。如果您打算在实践中部署这个模型，那么通过使用所有的数据并保持树的大小，您将使它更加精确。也就是说，既然您已经做出了所有的建模决策，就不需要保留验证数据了。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-28T16:30:39.134030Z",
     "iopub.status.busy": "2022-06-28T16:30:39.133483Z",
     "iopub.status.idle": "2022-06-28T16:30:39.158112Z",
     "shell.execute_reply": "2022-06-28T16:30:39.157087Z",
     "shell.execute_reply.started": "2022-06-28T16:30:39.134000Z"
    }
   },
   "outputs": [],
   "source": [
    "# 填写参数，使最佳大小和取消注释\n",
    "final_model = DecisionTreeRegressor(max_leaf_nodes=best_tree_size, random_state=1)\n",
    "\n",
    "# 拟合最终模型，取消后两行的注释\n",
    "final_model.fit(X, y)\n",
    "\n",
    "# Check your answer\n",
    "step_2.check()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-28T16:30:39.160080Z",
     "iopub.status.busy": "2022-06-28T16:30:39.159538Z",
     "iopub.status.idle": "2022-06-28T16:30:39.163600Z",
     "shell.execute_reply": "2022-06-28T16:30:39.162770Z",
     "shell.execute_reply.started": "2022-06-28T16:30:39.160048Z"
    }
   },
   "outputs": [],
   "source": [
    "# step_2.hint()\n",
    "# step_2.solution()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "您调整了这个模型并改进了结果。但是我们仍然在使用决策树模型，按照现代机器学习标准，这些模型并不十分复杂。在下一步中，您将学习如何使用随机森林来进一步改进您的模型。\n",
    "\n",
    "# 继续\n",
    "\n",
    "你已经准备好进入 **[Random Forests](https://www.kaggle.com/dansbecker/random-forests).**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "*Have questions or comments? Visit the [course discussion forum](https://www.kaggle.com/learn/intro-to-machine-learning/discussion) to chat with other learners.*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
